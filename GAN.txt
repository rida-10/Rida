GAN



import numpy as  np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
def build_generator(latent_dim):
    model = keras.Sequential()
    model.add(layers.Dense(256, input_dim=latent_dim))
    model.add(layers.LeakyReLU(alpha=0.2))
    model.add(layers.Dense(512))
    model.add(layers.LeakyReLU(alpha=0.2))
    model.add(layers.Dense(784, activation='tanh'))
    model.add(layers.Reshape((28, 28, 1)))
    return model
def build_discriminator():
    model = keras.Sequential()
    model.add(layers.Flatten(input_shape=(28, 28, 1)))
    model.add(layers.Dense(512))
    model.add(layers.LeakyReLU(alpha=0.2))
    model.add(layers.Dense(256))
    model.add(layers.LeakyReLU(alpha=0.2))
    model.add(layers.Dense(1, activation='sigmoid'))
    return model
def build_gan(generator, discriminator):
    discriminator.trainable = False
    model = keras.Sequential()
    model.add(generator)
    model.add(discriminator)
    return model
(x_train, _), (_, _) = keras.datasets.mnist.load_data()
x_train = x_train.reshape(-1, 28, 28, 1).astype('float32')
x_train = (x_train - 127.5) / 127.5
latent_dim = 100
epochs = 10000
batch_size = 128
generator = build_generator(latent_dim)
discriminator = build_discriminator()
gan = build_gan(generator, discriminator)
discriminator.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy')
gan.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy')
for epoch in range(epochs):
    noise = tf.random.normal((batch_size, latent_dim))
    generated_images = generator.predict(noise)
    real_images = x_train[np.random.choice(range(x_train.shape[0]), batch_size)]
    combined_images = np.concatenate([generated_images, real_images])
    labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])
    labels += 0.05 * np.random.random(labels.shape)  # Add noise to labels
    discriminator_loss = discriminator.train_on_batch(combined_images, labels)
    noise = tf.random.normal((batch_size, latent_dim))
    misleading_targets = np.zeros((batch_size, 1))
    generator_loss = gan.train_on_batch(noise, misleading_targets)
    if epoch % 100 == 0:
        print(f'Epoch {epoch}: Discriminator loss = {discriminator_loss}, Generator loss = {generator_loss}')
import matplotlib.pyplot as plt
noise = tf.random.normal((10, latent_dim))
generated_images = generator.predict(noise)
fig, axes = plt.subplots(1, 10, figsize=(10, 1))
for i, image in enumerate(generated_images):
    axes[i].imshow(image.reshape(28, 28), cmap='gray')
    axes[i].axis('off')
plt.show()